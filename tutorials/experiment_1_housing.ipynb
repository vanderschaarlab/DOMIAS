{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import warnings\n",
    "from typing import Union\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "from scipy import stats\n",
    "from scipy.stats import multivariate_normal\n",
    "from sdv.tabular import TVAE\n",
    "from sklearn.datasets import fetch_california_housing, fetch_covtype, load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# domias absolute\n",
    "from domias.evaluator import evaluate_performance\n",
    "from domias.models.ctgan import CTGAN\n",
    "from domias.models.generator import GeneratorInterface\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_dataset() -> np.ndarray:\n",
    "    def data_loader() -> np.ndarray:\n",
    "        scaler = StandardScaler()\n",
    "        X = fetch_california_housing().data\n",
    "        np.random.shuffle(X)\n",
    "        return scaler.fit_transform(X)\n",
    "\n",
    "    return data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(\n",
    "    gan_method: str = \"TVAE\",\n",
    "    epochs: int = 100,\n",
    "    seed: int = 0,\n",
    ") -> GeneratorInterface:\n",
    "    class LocalGenerator(GeneratorInterface):\n",
    "        def __init__(self) -> None:\n",
    "            if gan_method == \"TVAE\":\n",
    "                syn_model = TVAE(epochs=epochs)\n",
    "            elif gan_method == \"CTGAN\":\n",
    "                syn_model = CTGAN(epochs=epochs)\n",
    "            elif gan_method == \"KDE\":\n",
    "                syn_model = None\n",
    "            else:\n",
    "                raise RuntimeError()\n",
    "            self.method = gan_method\n",
    "            self.model = syn_model\n",
    "\n",
    "        def fit(self, data: pd.DataFrame) -> \"LocalGenerator\":\n",
    "            if self.method == \"KDE\":\n",
    "                self.model = stats.gaussian_kde(np.transpose(data))\n",
    "            else:\n",
    "                self.model.fit(data)\n",
    "\n",
    "            return self\n",
    "\n",
    "        def generate(self, count: int) -> pd.DataFrame:\n",
    "            if gan_method == \"KDE\":\n",
    "                samples = pd.DataFrame(self.model.resample(count).transpose(1, 0))\n",
    "            elif gan_method == \"TVAE\":\n",
    "                samples = self.model.sample(count)\n",
    "            elif gan_method == \"CTGAN\":\n",
    "                samples = self.model.generate(count)\n",
    "            else:\n",
    "                raise RuntimeError()\n",
    "\n",
    "            return samples\n",
    "\n",
    "    return LocalGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset()\n",
    "\n",
    "gen_size = 10000\n",
    "held_out_size = 10000\n",
    "training_epochs = [100, 500, 1000, 2000, 3000]\n",
    "training_sizes = [100, 500, 1000, 3000]\n",
    "\n",
    "method = \"TVAE\"\n",
    "density_estimator = \"prior\"  # prior, bnaf, kde\n",
    "\n",
    "results = {}\n",
    "for training_size in training_sizes:\n",
    "    results[training_size] = {}\n",
    "    for training_epoch in training_epochs:\n",
    "        generator = get_generator(\n",
    "            gan_method=method,\n",
    "            epochs=training_epoch,\n",
    "        )\n",
    "        perf = evaluate_performance(\n",
    "            generator,\n",
    "            dataset,\n",
    "            training_size,\n",
    "            held_out_size,\n",
    "            training_epoch,\n",
    "            synthetic_sizes=[gen_size],\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\"\"\n",
    "                SIZE_PARAM = {training_size} ADDITION_SIZE  = {held_out_size} TRAINING_EPOCH = {training_epoch}\n",
    "                    metrics = {perf[gen_size][\"MIA_performance\"]}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        results[training_size][training_epoch] = perf[gen_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import cloudpickle\n",
    "\n",
    "with open(\"experiment_1_results.bkp\", \"wb\") as f:\n",
    "    cloudpickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3637f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c9bc120",
   "metadata": {},
   "source": [
    "## AUC by the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98429ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = training_sizes[-1]\n",
    "\n",
    "output = pd.DataFrame([], columns=[\"epoch\", \"src\", \"aucroc\"])\n",
    "for training_epoch in training_epochs:\n",
    "    epoch_res = results[training_size][training_epoch]\n",
    "    perf = epoch_res[\"MIA_performance\"]\n",
    "\n",
    "    for key in perf:\n",
    "        output = pd.concat(\n",
    "            [\n",
    "                output,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        [training_epoch, key, perf[key][\"aucroc\"]],\n",
    "                    ],\n",
    "                    columns=[\"epoch\", \"src\", \"aucroc\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(output, x=\"epoch\", y=\"aucroc\", hue=\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43ace7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "098aac49",
   "metadata": {},
   "source": [
    "## Accuracy by number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b20cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = training_sizes[-1]\n",
    "\n",
    "output = pd.DataFrame([], columns=[\"epoch\", \"src\", \"accuracy\"])\n",
    "for training_epoch in training_epochs:\n",
    "    epoch_res = results[training_size][training_epoch]\n",
    "    perf = epoch_res[\"MIA_performance\"]\n",
    "\n",
    "    for key in perf:\n",
    "        output = pd.concat(\n",
    "            [\n",
    "                output,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        [training_epoch, key, perf[key][\"accuracy\"]],\n",
    "                    ],\n",
    "                    columns=[\"epoch\", \"src\", \"accuracy\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(output, x=\"epoch\", y=\"accuracy\", hue=\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eefca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f056e24",
   "metadata": {},
   "source": [
    "## AUC by the training dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = training_epochs[-1]\n",
    "\n",
    "output = pd.DataFrame([], columns=[\"training_size\", \"src\", \"aucroc\"])\n",
    "\n",
    "for training_size in training_sizes:\n",
    "    epoch_res = results[training_size][training_epoch]\n",
    "    perf = epoch_res[\"MIA_performance\"]\n",
    "\n",
    "    for key in perf:\n",
    "        output = pd.concat(\n",
    "            [\n",
    "                output,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        [training_size, key, perf[key][\"aucroc\"]],\n",
    "                    ],\n",
    "                    columns=[\"training_size\", \"src\", \"aucroc\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(output, x=\"training_size\", y=\"aucroc\", hue=\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b140b39",
   "metadata": {},
   "source": [
    "## Accuracy by the training dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e52352",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = training_epochs[-1]\n",
    "\n",
    "output = pd.DataFrame([], columns=[\"training_size\", \"src\", \"accuracy\"])\n",
    "\n",
    "for training_size in training_sizes:\n",
    "    epoch_res = results[training_size][training_epoch]\n",
    "    perf = epoch_res[\"MIA_performance\"]\n",
    "\n",
    "    for key in perf:\n",
    "        output = pd.concat(\n",
    "            [\n",
    "                output,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        [training_size, key, perf[key][\"accuracy\"]],\n",
    "                    ],\n",
    "                    columns=[\"training_size\", \"src\", \"accuracy\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(output, x=\"training_size\", y=\"accuracy\", hue=\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f7eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
